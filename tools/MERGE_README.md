# ä¿é™©å‘ç‚¹åˆå¹¶å·¥å…·

è¿™ä¸ªå·¥å…·ç”¨äºå°†AIæå–çš„ä¿é™©å‘ç‚¹æ•°æ®ä¸ç°æœ‰çš„ä¿é™©å‘ç‚¹æ•°æ®åˆå¹¶ï¼Œå»é™¤é‡å¤é¡¹å¹¶é‡æ–°åˆ†é…ç¼–å·ã€‚

## ğŸ¯ åŠŸèƒ½ç‰¹ç‚¹

- âœ… **æ™ºèƒ½åˆå¹¶**: è‡ªåŠ¨åˆå¹¶ä¸¤ä¸ªJSONæ–‡ä»¶çš„å‘ç‚¹æ•°æ®
- âœ… **å»é‡å¤„ç†**: åŸºäºæ ‡é¢˜è‡ªåŠ¨è¯†åˆ«å¹¶å»é™¤é‡å¤é¡¹  
- âœ… **é‡æ–°ç¼–å·**: æŒ‰åˆ†ç±»é‡æ–°åˆ†é…è¿ç»­ç¼–å·
- âœ… **æ•°æ®éªŒè¯**: éªŒè¯æ–‡ä»¶æ ¼å¼å’Œæ•°æ®å®Œæ•´æ€§
- âœ… **è‡ªåŠ¨å¤‡ä»½**: è¾“å‡ºæ–‡ä»¶å­˜åœ¨æ—¶è‡ªåŠ¨åˆ›å»ºå¤‡ä»½
- âœ… **æ ¼å¼å…¼å®¹**: ä¿æŒä¸åŸå§‹JSONæ ¼å¼çš„å…¼å®¹æ€§

## ğŸ“ æ–‡ä»¶ç»“æ„

```
tools/
â”œâ”€â”€ merge_pits.py                     # æ ¸å¿ƒåˆå¹¶é€»è¾‘
â”œâ”€â”€ run_merge_pits.py                 # ç®€åŒ–è¿è¡Œè„šæœ¬
â””â”€â”€ MERGE_README.md                   # ä½¿ç”¨è¯´æ˜ï¼ˆæœ¬æ–‡ä»¶ï¼‰

data/
â”œâ”€â”€ pit_types_new.json                # è¾“å…¥ï¼šç°æœ‰å‘ç‚¹æ•°æ®
â”œâ”€â”€ insurance_pits_extracted.json     # è¾“å…¥ï¼šAIæå–çš„å‘ç‚¹æ•°æ®
â””â”€â”€ insurance_pits_merged.json        # è¾“å‡ºï¼šåˆå¹¶åçš„å‘ç‚¹æ•°æ®
```

## ğŸ“Š è¾“å…¥æ–‡ä»¶æ ¼å¼

### ç°æœ‰å‘ç‚¹æ•°æ® (`pit_types_new.json`)

```json
[
  {
    "category": "äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹",
    "items": [
      {
        "ç¼–å·": 1,
        "æ ‡é¢˜": "è´¹ç‡ä¸ä¿éšœè´£ä»»çš„ä¸å¯¹ç­‰æ¯”è¾ƒ",
        "ç¤ºä¾‹æè¿°": "ç”¨è‡ªå®¶ä¿éšœå·®ä½†ä¾¿å®œçš„äº§å“å»å¯¹æ¯”åˆ«å®¶ä¿éšœå¥½ä½†è´µçš„äº§å“ã€‚",
        "å‘ç‚¹åŸå› ": "è¿›è¡Œ"ç”°å¿Œèµ›é©¬"å¼çš„è¯¯å¯¼ï¼Œè®©å®¢æˆ·ä»¥ä¸ºå äº†ä¾¿å®œï¼Œå®é™…ä¿éšœæ‰“äº†æŠ˜æ‰£ã€‚"
      }
    ]
  }
]
```

### AIæå–çš„å‘ç‚¹æ•°æ® (`insurance_pits_extracted.json`)

```json
{
  "extraction_time": "2025-07-30T15:30:00",
  "total_categories": 3,
  "total_pits": 15,
  "processed_files": 5,
  "failed_files": [],
  "categories": [
    {
      "category": "äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹",
      "items": [
        {
          "ç¼–å·": 1,
          "æ ‡é¢˜": "é¦–å¹´ä½ä¿è´¹è¯¯å¯¼",
          "ç¤ºä¾‹æè¿°": "ä¿é™©å…¬å¸å®£ä¼ é¦–å¹´ä¿è´¹å¾ˆä¾¿å®œï¼Œä½†ä¸æåç»­ä¿è´¹å¤§å¹…ä¸Šæ¶¨",
          "å‘ç‚¹åŸå› ": "åˆ©ç”¨ä½ä»·è¯±é¥µè®©å®¢æˆ·å¿½ç•¥é•¿æœŸæˆæœ¬ï¼Œç»­ä¿æ—¶é¢ä¸´å·¨å¤§ç»æµå‹åŠ›"
        }
      ]
    }
  ]
}
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1ï¼šç®€åŒ–è¿è¡Œï¼ˆæ¨èï¼‰

```bash
cd tools
python run_merge_pits.py
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯å’Œå‘ç‚¹æ•°é‡
3. å±•ç¤ºåˆå¹¶è®¡åˆ’
4. è¯·æ±‚ç”¨æˆ·ç¡®è®¤
5. æ‰§è¡Œåˆå¹¶å¹¶æ˜¾ç¤ºç»“æœ

### æ–¹æ³•2ï¼šå‘½ä»¤è¡Œè¿è¡Œ

```bash
cd tools

# ä½¿ç”¨é»˜è®¤æ–‡ä»¶è·¯å¾„
python merge_pits.py

# æŒ‡å®šæ–‡ä»¶è·¯å¾„
python merge_pits.py \
  --extracted ../data/insurance_pits_extracted.json \
  --existing ../data/pit_types_new.json \
  --output ../data/insurance_pits_merged.json

# ä¸åˆ›å»ºå¤‡ä»½æ–‡ä»¶
python merge_pits.py --no-backup
```

### æ–¹æ³•3ï¼šç¨‹åºåŒ–ä½¿ç”¨

```python
from merge_pits import PitsMerger

# åˆ›å»ºåˆå¹¶å™¨
merger = PitsMerger()

# æ‰§è¡Œåˆå¹¶
success = merger.merge_files(
    extracted_file="../data/insurance_pits_extracted.json",
    existing_file="../data/pit_types_new.json", 
    output_file="../data/insurance_pits_merged.json"
)

if success:
    print("åˆå¹¶æˆåŠŸï¼")
```

## ğŸ“ˆ åˆå¹¶è¿‡ç¨‹

### 1. æ•°æ®åŠ è½½ä¸éªŒè¯

```
ğŸ“– åŠ è½½æ•°æ®æ–‡ä»¶...
âœ… æå–æ•°æ®: 3 ä¸ªåˆ†ç±»
âœ… ç°æœ‰æ•°æ®: 6 ä¸ªåˆ†ç±»
```

### 2. æŒ‰åˆ†ç±»åˆå¹¶

```
ğŸ“¥ åˆå¹¶ç°æœ‰æ•°æ®...
  â€¢ äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹: æ·»åŠ  15 ä¸ªç°æœ‰å‘ç‚¹
  â€¢ ä¿éšœè´£ä»»ä¸ç†èµ”æ¡æ¬¾ç›¸å…³å‘ç‚¹: æ·»åŠ  12 ä¸ªç°æœ‰å‘ç‚¹

ğŸ“¥ åˆå¹¶æå–æ•°æ®...
  â€¢ äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹: æ·»åŠ  8 ä¸ªæå–å‘ç‚¹
  â€¢ é”€å”®è¡Œä¸ºä¸ä¸“ä¸šä¼¦ç†ç›¸å…³å‘ç‚¹: æ·»åŠ  5 ä¸ªæå–å‘ç‚¹
```

### 3. å»é‡å¤„ç†

```
ğŸ” æ£€æŸ¥é‡å¤é¡¹...
  â€¢ äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹: å»é™¤ 2 ä¸ªé‡å¤é¡¹
  â€¢ é”€å”®è¡Œä¸ºä¸ä¸“ä¸šä¼¦ç†ç›¸å…³å‘ç‚¹: å»é™¤ 1 ä¸ªé‡å¤é¡¹
```

### 4. é‡æ–°ç¼–å·

```
ğŸ”¢ é‡æ–°åˆ†é…ç¼–å·...
  â€¢ äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹: 21 ä¸ªå‘ç‚¹ (ç¼–å· 1-21)
  â€¢ ä¿éšœè´£ä»»ä¸ç†èµ”æ¡æ¬¾ç›¸å…³å‘ç‚¹: 12 ä¸ªå‘ç‚¹ (ç¼–å· 1-12)
  â€¢ é”€å”®è¡Œä¸ºä¸ä¸“ä¸šä¼¦ç†ç›¸å…³å‘ç‚¹: 16 ä¸ªå‘ç‚¹ (ç¼–å· 1-16)
```

## ğŸ“Š è¾“å‡ºæ ¼å¼

åˆå¹¶åç”Ÿæˆçš„æ–‡ä»¶æ ¼å¼ï¼š

```json
{
  "merge_time": "2025-07-30T16:45:00.123456",
  "total_categories": 5,
  "total_pits": 67,
  "source_info": {
    "extraction_time": "2025-07-30T15:30:00",
    "processed_files": 15,
    "failed_files": []
  },
  "categories": [
    {
      "category": "äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹",
      "items": [
        {
          "ç¼–å·": 1,
          "æ ‡é¢˜": "è´¹ç‡ä¸ä¿éšœè´£ä»»çš„ä¸å¯¹ç­‰æ¯”è¾ƒ",
          "ç¤ºä¾‹æè¿°": "...",
          "å‘ç‚¹åŸå› ": "..."
        },
        {
          "ç¼–å·": 2,
          "æ ‡é¢˜": "é¦–å¹´ä½ä¿è´¹è¯¯å¯¼",
          "ç¤ºä¾‹æè¿°": "...",
          "å‘ç‚¹åŸå› ": "..."
        }
      ]
    }
  ]
}
```

### å­—æ®µè¯´æ˜

- **merge_time**: åˆå¹¶æ‰§è¡Œæ—¶é—´
- **total_categories**: åŒ…å«å‘ç‚¹çš„åˆ†ç±»æ€»æ•°
- **total_pits**: åˆå¹¶åçš„å‘ç‚¹æ€»æ•°
- **source_info**: åŸå§‹æå–æ•°æ®çš„å…ƒä¿¡æ¯
- **categories**: æŒ‰åˆ†ç±»æ•´ç†çš„å‘ç‚¹æ•°æ®
  - **ç¼–å·**: è¯¥åˆ†ç±»å†…çš„è¿ç»­ç¼–å·ï¼ˆä»1å¼€å§‹ï¼‰

## âš™ï¸ é…ç½®é€‰é¡¹

### å‘½ä»¤è¡Œå‚æ•°

| å‚æ•° | ç®€å†™ | æè¿° | é»˜è®¤å€¼ |
|------|------|------|--------|
| `--extracted` | `-e` | AIæå–çš„å‘ç‚¹æ–‡ä»¶ | `../data/insurance_pits_extracted.json` |
| `--existing` | `-x` | ç°æœ‰å‘ç‚¹æ–‡ä»¶ | `../data/pit_types_new.json` |
| `--output` | `-o` | è¾“å‡ºæ–‡ä»¶è·¯å¾„ | `../data/insurance_pits_merged.json` |
| `--no-backup` | `-n` | ä¸åˆ›å»ºå¤‡ä»½æ–‡ä»¶ | é»˜è®¤åˆ›å»ºå¤‡ä»½ |

### å»é‡è§„åˆ™

å½“å‰çš„å»é‡é€»è¾‘åŸºäº**æ ‡é¢˜å®Œå…¨åŒ¹é…**ï¼š

```python
# ç®€å•å»é‡ï¼šç›¸åŒæ ‡é¢˜è§†ä¸ºé‡å¤
seen_titles = set()
for item in items:
    title = item.get('æ ‡é¢˜', '').strip()
    if title not in seen_titles:
        seen_titles.add(title)
        unique_items.append(item)
```

### åˆ†ç±»é¡ºåº

å‘ç‚¹æŒ‰ç…§ä»¥ä¸‹å›ºå®šé¡ºåºæ’åˆ—ï¼š

1. äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹
2. ä¿éšœè´£ä»»ä¸ç†èµ”æ¡æ¬¾ç›¸å…³å‘ç‚¹
3. é”€å”®è¡Œä¸ºä¸ä¸“ä¸šä¼¦ç†ç›¸å…³å‘ç‚¹
4. ç»­ä¿ã€åœå”®ä¸äº§å“ç¨³å®šæ€§ç›¸å…³å‘ç‚¹
5. æ ¸ä¿ä¸å¥åº·å‘ŠçŸ¥ç›¸å…³å‘ç‚¹
6. å…¶ä»–å‘ç‚¹

## ğŸ§ª æµ‹è¯•ç¤ºä¾‹

### åˆ›å»ºæµ‹è¯•æ•°æ®

```bash
# åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
cat > ../data/test_extracted.json << 'EOF'
{
  "extraction_time": "2025-07-30T15:30:00",
  "total_categories": 1,
  "total_pits": 2,
  "categories": [
    {
      "category": "äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹",
      "items": [
        {
          "ç¼–å·": 1,
          "æ ‡é¢˜": "æµ‹è¯•å‘ç‚¹1",
          "ç¤ºä¾‹æè¿°": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å‘ç‚¹",
          "å‘ç‚¹åŸå› ": "ä»…ç”¨äºæµ‹è¯•"
        }
      ]
    }
  ]
}
EOF

# è¿è¡Œæµ‹è¯•åˆå¹¶
python merge_pits.py \
  --extracted ../data/test_extracted.json \
  --existing ../data/pit_types_new.json \
  --output ../data/test_merged.json
```

### éªŒè¯ç»“æœ

```bash
# æŸ¥çœ‹åˆå¹¶ç»Ÿè®¡
jq '.total_pits, .total_categories' ../data/test_merged.json

# æŸ¥çœ‹å„åˆ†ç±»æ•°é‡
jq '.categories[] | {category: .category, count: (.items | length)}' ../data/test_merged.json

# éªŒè¯ç¼–å·è¿ç»­æ€§
jq '.categories[0].items[] | .ç¼–å·' ../data/test_merged.json
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ–‡ä»¶å…¼å®¹æ€§

- æ”¯æŒä»»ä¸€æ–‡ä»¶ä¸å­˜åœ¨çš„æƒ…å†µï¼ˆä¼šè·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼‰
- è‡ªåŠ¨å¤„ç†ä¸åŒçš„JSONæ ¼å¼ç»“æ„
- ä¿æŒä¸åŸå§‹æ•°æ®æ ¼å¼çš„å…¼å®¹æ€§

### 2. å»é‡é™åˆ¶

- å½“å‰ä»…åŸºäºæ ‡é¢˜è¿›è¡Œå»é‡
- æ ‡é¢˜ç›¸åŒä½†æè¿°ä¸åŒçš„å‘ç‚¹ä¼šè¢«è§†ä¸ºé‡å¤
- å»ºè®®äººå·¥å®¡æ ¸å»é‡ç»“æœ

### 3. æ•°æ®å®Œæ•´æ€§

- åˆå¹¶è¿‡ç¨‹ä¼šéªŒè¯å¿…éœ€å­—æ®µçš„å­˜åœ¨
- ç¼ºå°‘å…³é”®å­—æ®µçš„å‘ç‚¹ä¼šè¢«è·³è¿‡
- å»ºè®®åœ¨åˆå¹¶åè¿›è¡Œæ•°æ®è´¨é‡æ£€æŸ¥

### 4. å¤‡ä»½æœºåˆ¶

- è¾“å‡ºæ–‡ä»¶å­˜åœ¨æ—¶ä¼šè‡ªåŠ¨åˆ›å»º `.backup.json` æ–‡ä»¶
- ä½¿ç”¨ `--no-backup` å¯ä»¥è·³è¿‡å¤‡ä»½åˆ›å»º
- å»ºè®®ä¿ç•™å¤‡ä»½æ–‡ä»¶ç›´åˆ°ç¡®è®¤åˆå¹¶ç»“æœæ­£ç¡®

## ğŸ”§ è‡ªå®šä¹‰æ‰©å±•

### å¢å¼ºå»é‡é€»è¾‘

```python
def enhanced_remove_duplicates(self, merged_data):
    """å¢å¼ºçš„å»é‡é€»è¾‘"""
    for category, items in merged_data.items():
        unique_items = []
        
        for item in items:
            title = item.get('æ ‡é¢˜', '').strip()
            description = item.get('ç¤ºä¾‹æè¿°', '').strip()
            
            # æ£€æŸ¥æ ‡é¢˜å’Œæè¿°çš„ç›¸ä¼¼æ€§
            is_duplicate = False
            for existing in unique_items:
                if self.is_similar(title, existing.get('æ ‡é¢˜', '')):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_items.append(item)
        
        merged_data[category] = unique_items
```

### æ·»åŠ æ–°åˆ†ç±»

```python
# ä¿®æ”¹ merge_pits.py ä¸­çš„åˆ†ç±»å®šä¹‰
self.categories = [
    "äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹",
    "ä¿éšœè´£ä»»ä¸ç†èµ”æ¡æ¬¾ç›¸å…³å‘ç‚¹",
    "é”€å”®è¡Œä¸ºä¸ä¸“ä¸šä¼¦ç†ç›¸å…³å‘ç‚¹",
    "ç»­ä¿ã€åœå”®ä¸äº§å“ç¨³å®šæ€§ç›¸å…³å‘ç‚¹",
    "æ ¸ä¿ä¸å¥åº·å‘ŠçŸ¥ç›¸å…³å‘ç‚¹",
    "ä½ çš„æ–°åˆ†ç±»",  # æ·»åŠ æ–°åˆ†ç±»
    "å…¶ä»–å‘ç‚¹"
]
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯

#### 1. æ–‡ä»¶æ ¼å¼é”™è¯¯

```bash
âŒ JSONæ ¼å¼é”™è¯¯: ../data/insurance_pits_extracted.json - Expecting ',' delimiter

# è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥JSONè¯­æ³•
python -m json.tool ../data/insurance_pits_extracted.json
```

#### 2. æ–‡ä»¶ä¸å­˜åœ¨

```bash
âŒ è¾“å…¥æ–‡ä»¶éƒ½ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œåˆå¹¶

# è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥æ–‡ä»¶è·¯å¾„
ls -la ../data/insurance_pits_*.json
ls -la ../data/pit_types_new.json
```

#### 3. æƒé™é”™è¯¯

```bash
âŒ ä¿å­˜å¤±è´¥: [Errno 13] Permission denied

# è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥ç›®å½•æƒé™
chmod 755 ../data
```

### è°ƒè¯•æŠ€å·§

```bash
# 1. éªŒè¯è¾“å…¥æ–‡ä»¶æ ¼å¼
python -c "
import json
with open('../data/pit_types_new.json') as f:
    data = json.load(f)
print(f'Categories: {len(data)}')
print(f'Total items: {sum(len(cat[\"items\"]) for cat in data)}')
"

# 2. æ£€æŸ¥åˆå¹¶ç»“æœ
python -c "
from merge_pits import PitsMerger
merger = PitsMerger()
merger.merge_files(
    '../data/insurance_pits_extracted.json',
    '../data/pit_types_new.json', 
    '../data/debug_merged.json'
)
"

# 3. æ¯”è¾ƒåˆå¹¶å‰åçš„æ•°æ®
diff <(jq -S . ../data/pit_types_new.json) <(jq -S '.categories' ../data/insurance_pits_merged.json)
```

## ğŸ“‹ ä½¿ç”¨æ£€æŸ¥æ¸…å•

åˆå¹¶å‰æ£€æŸ¥ï¼š
- [ ] ç¡®è®¤è¾“å…¥æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
- [ ] å¤‡ä»½é‡è¦çš„ç°æœ‰æ•°æ®æ–‡ä»¶
- [ ] ç¡®è®¤è¾“å‡ºç›®å½•æœ‰å†™å…¥æƒé™

åˆå¹¶åéªŒè¯ï¼š
- [ ] æ£€æŸ¥æ€»å‘ç‚¹æ•°æ˜¯å¦åˆç†
- [ ] éªŒè¯å„åˆ†ç±»çš„ç¼–å·æ˜¯å¦è¿ç»­
- [ ] äººå·¥æŠ½æŸ¥åˆå¹¶è´¨é‡
- [ ] ç¡®è®¤æ²¡æœ‰é‡è¦æ•°æ®ä¸¢å¤±

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. **æŸ¥çœ‹è¯¦ç»†æ—¥å¿—**: è¿è¡Œæ—¶çš„è¾“å‡ºåŒ…å«è¯¦ç»†çš„å¤„ç†ä¿¡æ¯
2. **éªŒè¯æ–‡ä»¶æ ¼å¼**: ä½¿ç”¨ `jq` æˆ– `python -m json.tool` æ£€æŸ¥JSONæ ¼å¼
3. **æ£€æŸ¥æƒé™**: ç¡®ä¿å¯¹è¾“å…¥å’Œè¾“å‡ºç›®å½•æœ‰é€‚å½“çš„è¯»å†™æƒé™
4. **æµ‹è¯•å°æ•°æ®é›†**: å…ˆç”¨å°‘é‡æ•°æ®æµ‹è¯•åˆå¹¶é€»è¾‘

## ğŸ“ æ›´æ–°æ—¥å¿—

- **v1.0** (2025-07-30): åˆå§‹ç‰ˆæœ¬
  - åŸºæœ¬åˆå¹¶åŠŸèƒ½
  - æ ‡é¢˜å»é‡
  - è‡ªåŠ¨ç¼–å·åˆ†é…
  - å¤‡ä»½æœºåˆ¶
  - äº¤äº’å¼ç•Œé¢ 