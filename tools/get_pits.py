#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿é™©å‘ç‚¹æå–å™¨
ä½¿ç”¨DeepSeek APIä»æ–‡ç« ä¸­æå–ä¿é™©å‘ç‚¹ï¼Œå¹¶æŒ‰ç…§é¢„å®šä¹‰çš„åˆ†ç±»è¿›è¡Œæ•´ç†
"""

import json
import os
import time
import re
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import requests


class InsurancePitExtractor:
    """ä¿é™©å‘ç‚¹æå–å™¨"""
    
    def __init__(self, api_key: str = None, text_dir: str = "../data/text"):
        self.text_dir = Path(text_dir)
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡æˆ–ä¼ å…¥api_keyå‚æ•°")
        
        # DeepSeek APIé…ç½®
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # å‘ç‚¹åˆ†ç±»å®šä¹‰
        self.categories = [
            "äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹",
            "ä¿éšœè´£ä»»ä¸ç†èµ”æ¡æ¬¾ç›¸å…³å‘ç‚¹", 
            "é”€å”®è¡Œä¸ºä¸ä¸“ä¸šä¼¦ç†ç›¸å…³å‘ç‚¹",
            "ç»­ä¿ã€åœå”®ä¸äº§å“ç¨³å®šæ€§ç›¸å…³å‘ç‚¹",
            "æ ¸ä¿ä¸å¥åº·å‘ŠçŸ¥ç›¸å…³å‘ç‚¹",
            "å…¶ä»–å‘ç‚¹"
        ]
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.processed_files = 0
        self.total_pits_found = 0
        self.failed_files = []
        
    def create_extraction_prompt(self, article_content: str) -> str:
        """åˆ›å»ºå‘ç‚¹æå–çš„æç¤ºè¯"""
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹ä¿é™©ç›¸å…³æ–‡ç« ï¼Œæå–å…¶ä¸­æåˆ°çš„ä¿é™©å‘ç‚¹ã€é™·é˜±ã€è¯¯å¯¼æ€§é”€å”®è¡Œä¸ºç­‰é—®é¢˜ã€‚å¦‚æœæ–‡ç« æ²¡æœ‰æ˜æ˜¾æåŠå‘ç‚¹ï¼Œè¯·è¿”å›ç©ºæ•°ç»„[]ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹6ä¸ªåˆ†ç±»è¿›è¡Œæ•´ç†ï¼š
1. äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹ - æ¶‰åŠäº§å“å¯¹æ¯”ã€ä»·æ ¼ã€è´¹ç‡æ–¹é¢çš„è¯¯å¯¼
2. ä¿éšœè´£ä»»ä¸ç†èµ”æ¡æ¬¾ç›¸å…³å‘ç‚¹ - æ¶‰åŠä¿éšœèŒƒå›´ã€ç†èµ”æ¡ä»¶ã€å…è´£æ¡æ¬¾ç­‰æ–¹é¢çš„é—®é¢˜
3. é”€å”®è¡Œä¸ºä¸ä¸“ä¸šä¼¦ç†ç›¸å…³å‘ç‚¹ - æ¶‰åŠé”€å”®äººå‘˜çš„ä¸å½“è¡Œä¸ºã€è¯¯å¯¼æ€§å®£ä¼ ç­‰
4. ç»­ä¿ã€åœå”®ä¸äº§å“ç¨³å®šæ€§ç›¸å…³å‘ç‚¹ - æ¶‰åŠäº§å“ç»­ä¿ã€åœå”®ã€ç¨³å®šæ€§ç­‰æ–¹é¢çš„é—®é¢˜
5. æ ¸ä¿ä¸å¥åº·å‘ŠçŸ¥ç›¸å…³å‘ç‚¹ - æ¶‰åŠå¥åº·å‘ŠçŸ¥ã€æ ¸ä¿å®¡æŸ¥ç­‰æ–¹é¢çš„é—®é¢˜
6. å…¶ä»–å‘ç‚¹ - ä¸å±äºä»¥ä¸Šåˆ†ç±»çš„å…¶ä»–ä¿é™©ç›¸å…³å‘ç‚¹

å¯¹äºæ¯ä¸ªå‘ç‚¹ï¼Œè¯·æä¾›ï¼š
- æ ‡é¢˜ï¼šç®€æ´æ¦‚æ‹¬è¿™ä¸ªå‘ç‚¹ï¼Œè¦æ±‚æ˜¯ä¸€å¥å®¹æ˜“å¼•èµ·è¯¯å¯¼çš„è¡¨è¿°
- ç¤ºä¾‹æè¿°ï¼šå…·ä½“çš„å‘ç‚¹è¡¨ç°å½¢å¼æˆ–æ¡ˆä¾‹
- å‘ç‚¹åŸå› ï¼šä¸ºä»€ä¹ˆè¿™æ˜¯ä¸ªå‘ï¼Œä¼šé€ æˆä»€ä¹ˆé—®é¢˜

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```json
[
  {{
    "category": "åˆ†ç±»åç§°",
    "items": [
      {{
        "æ ‡é¢˜": "å‘ç‚¹æ ‡é¢˜",
        "ç¤ºä¾‹æè¿°": "å…·ä½“æè¿°",
        "å‘ç‚¹åŸå› ": "é€ æˆé—®é¢˜çš„åŸå› "
      }}
    ]
  }}
]
```

æ–‡ç« å†…å®¹ï¼š
{article_content}

è¯·ä»”ç»†åˆ†ææ–‡ç« å†…å®¹ï¼Œæå–æ‰€æœ‰æåˆ°çš„ä¿é™©å‘ç‚¹ã€‚å¦‚æœæ–‡ç« ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°å‘ç‚¹ï¼Œè¯·è¿”å›ç©ºæ•°ç»„[]ã€‚
"""
        return prompt
    
    def call_deepseek_api(self, prompt: str, max_retries: int = 3) -> Optional[str]:
        """è°ƒç”¨DeepSeek API"""
        for attempt in range(max_retries):
            try:
                payload = {
                    "model": "deepseek-chat",
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": 0.3,
                    "max_tokens": 4000
                }
                
                print(f"    ğŸ¤– è°ƒç”¨DeepSeek API (å°è¯• {attempt + 1}/{max_retries})")
                response = requests.post(self.api_url, headers=self.headers, json=payload, timeout=60)
                response.raise_for_status()
                
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                # æå–JSONéƒ¨åˆ†
                json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
                if json_match:
                    return json_match.group(1)
                else:
                    # å¦‚æœæ²¡æœ‰ä»£ç å—æ ‡è®°ï¼Œå°è¯•ç›´æ¥è§£æ
                    return content.strip()
                
            except requests.exceptions.RequestException as e:
                print(f"    âŒ APIè¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            except Exception as e:
                print(f"    âŒ å¤„ç†å“åº”å¤±è´¥: {e}")
                break
        
        return None
    
    def parse_extraction_result(self, result_text: str) -> List[Dict[str, Any]]:
        """è§£æAPIè¿”å›çš„ç»“æœ"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            pits_data = json.loads(result_text)
            
            # éªŒè¯æ•°æ®æ ¼å¼
            if isinstance(pits_data, list):
                validated_data = []
                for category_data in pits_data:
                    if isinstance(category_data, dict) and 'category' in category_data and 'items' in category_data:
                        # éªŒè¯åˆ†ç±»åç§°
                        if category_data['category'] in self.categories:
                            validated_items = []
                            for item in category_data.get('items', []):
                                if isinstance(item, dict) and all(key in item for key in ['æ ‡é¢˜', 'ç¤ºä¾‹æè¿°', 'å‘ç‚¹åŸå› ']):
                                    validated_items.append(item)
                            
                            if validated_items:
                                validated_data.append({
                                    'category': category_data['category'],
                                    'items': validated_items
                                })
                
                return validated_data
            
        except json.JSONDecodeError as e:
            print(f"    âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"    åŸå§‹å†…å®¹: {result_text[:200]}...")
        
        return []
    
    def read_article_content(self, file_path: Path) -> Optional[str]:
        """è¯»å–æ–‡ç« å†…å®¹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è·³è¿‡æ–‡ä»¶å¤´éƒ¨çš„å…ƒæ•°æ®ï¼Œåªæå–æ­£æ–‡å†…å®¹
            lines = content.split('\n')
            content_start_idx = 0
            
            for i, line in enumerate(lines):
                if line.strip() == '=' * 80:  # æ‰¾åˆ°åˆ†éš”çº¿
                    content_start_idx = i + 1
                    break
            
            article_content = '\n'.join(lines[content_start_idx:]).strip()
            
            # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…API tokenè¶…é™
            if len(article_content) > 8000:
                article_content = article_content[:8000] + "..."
            
            return article_content
            
        except Exception as e:
            print(f"    âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def extract_pits_from_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """ä»å•ä¸ªæ–‡ä»¶æå–å‘ç‚¹"""
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {file_path.name}")
        
        # è¯»å–æ–‡ç« å†…å®¹
        article_content = self.read_article_content(file_path)
        if not article_content:
            return []
        
        print(f"    ğŸ“ æ–‡ç« é•¿åº¦: {len(article_content)} å­—ç¬¦")
        
        # åˆ›å»ºæå–æç¤ºè¯
        prompt = self.create_extraction_prompt(article_content)
        
        # è°ƒç”¨API
        result_text = self.call_deepseek_api(prompt)
        if not result_text:
            print(f"    âŒ APIè°ƒç”¨å¤±è´¥")
            self.failed_files.append(str(file_path))
            return []
        
        # è§£æç»“æœ
        pits_data = self.parse_extraction_result(result_text)
        
        if pits_data:
            total_pits = sum(len(category['items']) for category in pits_data)
            print(f"    âœ… æå–åˆ° {total_pits} ä¸ªå‘ç‚¹")
            self.total_pits_found += total_pits
        else:
            print(f"    â„¹ï¸  æœªå‘ç°æ˜æ˜¾å‘ç‚¹")
        
        return pits_data
    
    def merge_pits_data(self, all_pits_data: List[List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """åˆå¹¶æ‰€æœ‰æ–‡ä»¶çš„å‘ç‚¹æ•°æ®"""
        merged_data = {}
        pit_counter = {}
        
        # åˆå§‹åŒ–åˆ†ç±»
        for category in self.categories:
            merged_data[category] = []
            pit_counter[category] = 0
        
        # åˆå¹¶æ•°æ®
        for file_pits in all_pits_data:
            for category_data in file_pits:
                category = category_data['category']
                if category in merged_data:
                    for item in category_data['items']:
                        pit_counter[category] += 1
                        item['ç¼–å·'] = pit_counter[category]
                        merged_data[category].append(item)
        
        # è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼
        result = []
        for category in self.categories:
            if merged_data[category]:
                result.append({
                    'category': category,
                    'items': merged_data[category]
                })
        
        return result
    
    def save_results(self, pits_data: List[Dict[str, Any]], output_file: str):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        try:
            # æ·»åŠ å…ƒæ•°æ®
            output_data = {
                'extraction_time': datetime.now().isoformat(),
                'total_categories': len(pits_data),
                'total_pits': sum(len(category['items']) for category in pits_data),
                'processed_files': self.processed_files,
                'failed_files': self.failed_files,
                'categories': pits_data
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    def process_all_files(self, max_files: Optional[int] = None) -> List[Dict[str, Any]]:
        """å¤„ç†æ‰€æœ‰æ–‡æœ¬æ–‡ä»¶"""
        print(f"ğŸš€ å¼€å§‹å¤„ç†ä¿é™©å‘ç‚¹æå–")
        print(f"ğŸ“ æ–‡æœ¬ç›®å½•: {self.text_dir}")
        print(f"ğŸ¤– ä½¿ç”¨API: DeepSeek")
        print("=" * 60)
        
        # æŸ¥æ‰¾æ‰€æœ‰txtæ–‡ä»¶
        txt_files = list(self.text_dir.glob("*.txt"))
        # è¿‡æ»¤æ‰æŠ¥å‘Šæ–‡ä»¶
        txt_files = [f for f in txt_files if not f.name.startswith('extraction_report')]
        
        if not txt_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡æœ¬æ–‡ä»¶")
            return []
        
        if max_files:
            txt_files = txt_files[:max_files]
            print(f"ğŸ”¢ é™åˆ¶å¤„ç†æ•°é‡: {max_files}")
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(txt_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶")
        print("=" * 60)
        
        all_pits_data = []
        
        for i, file_path in enumerate(txt_files, 1):
            print(f"\nğŸ“– å¤„ç†ç¬¬ {i}/{len(txt_files)} ä¸ªæ–‡ä»¶")
            
            pits_data = self.extract_pits_from_file(file_path)
            if pits_data:
                all_pits_data.append(pits_data)
            
            self.processed_files += 1
            
            # APIè°ƒç”¨é—´éš”
            if i < len(txt_files):
                print(f"    â±ï¸  ç­‰å¾… 2 ç§’...")
                time.sleep(2)
        
        # åˆå¹¶ç»“æœ
        print(f"\nğŸ”„ åˆå¹¶æ‰€æœ‰æå–ç»“æœ...")
        merged_results = self.merge_pits_data(all_pits_data)
        
        return merged_results
    
    def print_summary(self, results: List[Dict[str, Any]]):
        """æ‰“å°æå–æ‘˜è¦"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æå–å®Œæˆç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"å¤„ç†æ–‡ä»¶æ•°: {self.processed_files}")
        print(f"æ€»å‘ç‚¹æ•°: {self.total_pits_found}")
        print(f"å¤±è´¥æ–‡ä»¶æ•°: {len(self.failed_files)}")
        
        if results:
            print(f"\nğŸ“‹ åˆ†ç±»ç»Ÿè®¡:")
            for category_data in results:
                category = category_data['category']
                count = len(category_data['items'])
                print(f"  â€¢ {category}: {count} ä¸ª")
        
        if self.failed_files:
            print(f"\nâš ï¸  å¤„ç†å¤±è´¥çš„æ–‡ä»¶:")
            for failed_file in self.failed_files:
                print(f"  â€¢ {failed_file}")
        
        print(f"{'='*60}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä»æ–‡æœ¬æ–‡ä»¶ä¸­æå–ä¿é™©å‘ç‚¹')
    parser.add_argument('--text-dir', '-d',
                       default='../data/text',
                       help='æ–‡æœ¬æ–‡ä»¶ç›®å½•')
    parser.add_argument('--output', '-o',
                       default='../data/insurance_pits_extracted.json',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-files', '-m',
                       type=int,
                       help='é™åˆ¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('--api-key', '-k',
                       help='DeepSeek APIå¯†é’¥ï¼ˆä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡DEEPSEEK_API_KEYè®¾ç½®ï¼‰')
    parser.add_argument('--test', '-t',
                       action='store_true',
                       help='æµ‹è¯•æ¨¡å¼ï¼Œåªå¤„ç†å‰3ä¸ªæ–‡ä»¶')
    
    args = parser.parse_args()
    
    if args.test:
        args.max_files = 3
        print("ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰3ä¸ªæ–‡ä»¶")
    
    # æ£€æŸ¥æ–‡æœ¬ç›®å½•
    text_dir = Path(args.text_dir)
    if not text_dir.exists():
        print(f"âŒ æ–‡æœ¬ç›®å½•ä¸å­˜åœ¨: {text_dir}")
        print("è¯·å…ˆè¿è¡Œæ–‡ç« å†…å®¹æå–å·¥å…·")
        return
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = args.api_key or os.getenv('DEEPSEEK_API_KEY')
    if not api_key:
        print("âŒ è¯·è®¾ç½®DeepSeek APIå¯†é’¥")
        print("æ–¹æ³•1: export DEEPSEEK_API_KEY='your_api_key'")
        print("æ–¹æ³•2: python get_pits.py --api-key your_api_key")
        return
    
    try:
        # åˆ›å»ºæå–å™¨
        extractor = InsurancePitExtractor(api_key=api_key, text_dir=args.text_dir)
        
        # å¼€å§‹å¤„ç†
        start_time = datetime.now()
        results = extractor.process_all_files(max_files=args.max_files)
        end_time = datetime.now()
        
        # ä¿å­˜ç»“æœ
        if results:
            extractor.save_results(results, args.output)
        
        # æ˜¾ç¤ºæ‘˜è¦
        extractor.print_summary(results)
        
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {end_time - start_time}")
        
        if results:
            print(f"ğŸ‰ å¤„ç†å®Œæˆï¼å‘ç‚¹æ•°æ®å·²ä¿å­˜åˆ°: {args.output}")
        else:
            print("â„¹ï¸  æœªæå–åˆ°ä»»ä½•å‘ç‚¹æ•°æ®")
        
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 