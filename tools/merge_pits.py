#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿é™©å‘ç‚¹åˆå¹¶è„šæœ¬
å°† insurance_pits_extracted.json å’Œ pit_types_new.json åˆå¹¶ï¼Œå¹¶é‡æ–°åˆ†é…ç¼–å·
"""

import json
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any


class PitsMerger:
    """ä¿é™©å‘ç‚¹åˆå¹¶å™¨"""
    
    def __init__(self):
        self.categories = [
            "äº§å“æ¯”è¾ƒä¸è´¹ç‡ç›¸å…³å‘ç‚¹",
            "ä¿éšœè´£ä»»ä¸ç†èµ”æ¡æ¬¾ç›¸å…³å‘ç‚¹",
            "é”€å”®è¡Œä¸ºä¸ä¸“ä¸šä¼¦ç†ç›¸å…³å‘ç‚¹",
            "ç»­ä¿ã€åœå”®ä¸äº§å“ç¨³å®šæ€§ç›¸å…³å‘ç‚¹",
            "æ ¸ä¿ä¸å¥åº·å‘ŠçŸ¥ç›¸å…³å‘ç‚¹",
            "å…¶ä»–å‘ç‚¹"
        ]
    
    def load_json_file(self, file_path: str) -> Any:
        """åŠ è½½JSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        except json.JSONDecodeError as e:
            print(f"âŒ JSONæ ¼å¼é”™è¯¯: {file_path} - {e}")
            return None
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {file_path} - {e}")
            return None
    
    def normalize_extracted_data(self, extracted_data: Dict) -> List[Dict]:
        """æ ‡å‡†åŒ–æå–çš„æ•°æ®æ ¼å¼"""
        if not extracted_data or 'categories' not in extracted_data:
            return []
        
        return extracted_data['categories']
    
    def normalize_existing_data(self, existing_data: List) -> List[Dict]:
        """æ ‡å‡†åŒ–ç°æœ‰æ•°æ®æ ¼å¼"""
        if not existing_data or not isinstance(existing_data, list):
            return []
        
        return existing_data
    
    def merge_categories(self, extracted_data: List[Dict], existing_data: List[Dict]) -> Dict[str, List]:
        """åˆå¹¶åˆ†ç±»æ•°æ®"""
        merged_data = {}
        
        # åˆå§‹åŒ–æ‰€æœ‰åˆ†ç±»
        for category in self.categories:
            merged_data[category] = []
        
        # æ·»åŠ ç°æœ‰æ•°æ®
        print("ğŸ“¥ åˆå¹¶ç°æœ‰æ•°æ®...")
        for category_data in existing_data:
            category = category_data.get('category', '')
            if category in merged_data:
                items = category_data.get('items', [])
                merged_data[category].extend(items)
                print(f"  â€¢ {category}: æ·»åŠ  {len(items)} ä¸ªç°æœ‰å‘ç‚¹")
        
        # æ·»åŠ æå–çš„æ•°æ®
        print("ğŸ“¥ åˆå¹¶æå–æ•°æ®...")
        for category_data in extracted_data:
            category = category_data.get('category', '')
            if category in merged_data:
                items = category_data.get('items', [])
                merged_data[category].extend(items)
                print(f"  â€¢ {category}: æ·»åŠ  {len(items)} ä¸ªæå–å‘ç‚¹")
        
        return merged_data
    
    def remove_duplicates(self, merged_data: Dict[str, List]) -> Dict[str, List]:
        """å»é™¤é‡å¤é¡¹ï¼ˆåŸºäºæ ‡é¢˜ç›¸ä¼¼æ€§ï¼‰"""
        print("ğŸ” æ£€æŸ¥é‡å¤é¡¹...")
        
        for category, items in merged_data.items():
            if not items:
                continue
            
            # ç®€å•çš„é‡å¤æ£€æµ‹ï¼šåŸºäºæ ‡é¢˜
            seen_titles = set()
            unique_items = []
            duplicates = 0
            
            for item in items:
                title = item.get('æ ‡é¢˜', '').strip()
                if title and title not in seen_titles:
                    seen_titles.add(title)
                    unique_items.append(item)
                else:
                    duplicates += 1
            
            merged_data[category] = unique_items
            
            if duplicates > 0:
                print(f"  â€¢ {category}: å»é™¤ {duplicates} ä¸ªé‡å¤é¡¹")
        
        return merged_data
    
    def reassign_numbers(self, merged_data: Dict[str, List]) -> List[Dict]:
        """é‡æ–°åˆ†é…ç¼–å·"""
        print("ğŸ”¢ é‡æ–°åˆ†é…ç¼–å·...")
        
        result = []
        
        for category in self.categories:
            items = merged_data.get(category, [])
            if not items:
                continue
            
            # é‡æ–°åˆ†é…ç¼–å·
            for i, item in enumerate(items, 1):
                item['ç¼–å·'] = i
            
            result.append({
                'category': category,
                'items': items
            })
            
            print(f"  â€¢ {category}: {len(items)} ä¸ªå‘ç‚¹ (ç¼–å· 1-{len(items)})")
        
        return result
    
    def save_merged_data(self, merged_data: List[Dict], output_file: str, 
                        extracted_metadata: Dict = None):
        """ä¿å­˜åˆå¹¶åçš„æ•°æ®"""
        # æ„å»ºè¾“å‡ºæ•°æ®
        output_data = {
            'merge_time': datetime.now().isoformat(),
            'total_categories': len(merged_data),
            'total_pits': sum(len(cat['items']) for cat in merged_data),
            'categories': merged_data
        }
        
        # æ·»åŠ åŸå§‹æå–çš„å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        if extracted_metadata:
            output_data['source_info'] = {
                'extraction_time': extracted_metadata.get('extraction_time'),
                'processed_files': extracted_metadata.get('processed_files'),
                'failed_files': extracted_metadata.get('failed_files', [])
            }
        
        # ä¿å­˜æ–‡ä»¶
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ åˆå¹¶ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False
    
    def print_summary(self, merged_data: List[Dict]):
        """æ‰“å°åˆå¹¶æ‘˜è¦"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š åˆå¹¶å®Œæˆç»Ÿè®¡")
        print(f"{'='*60}")
        
        total_pits = sum(len(cat['items']) for cat in merged_data)
        print(f"æ€»åˆ†ç±»æ•°: {len(merged_data)}")
        print(f"æ€»å‘ç‚¹æ•°: {total_pits}")
        
        print(f"\nğŸ“‹ å„åˆ†ç±»ç»Ÿè®¡:")
        for category_data in merged_data:
            category = category_data['category']
            count = len(category_data['items'])
            print(f"  â€¢ {category}: {count} ä¸ª")
        
        print(f"{'='*60}")
    
    def merge_files(self, extracted_file: str, existing_file: str, output_file: str):
        """åˆå¹¶ä¸¤ä¸ªæ–‡ä»¶"""
        print("ğŸš€ å¼€å§‹åˆå¹¶ä¿é™©å‘ç‚¹æ•°æ®")
        print(f"ğŸ“„ æå–æ–‡ä»¶: {extracted_file}")
        print(f"ğŸ“„ ç°æœ‰æ–‡ä»¶: {existing_file}")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print("=" * 60)
        
        # åŠ è½½æ–‡ä»¶
        print("ğŸ“– åŠ è½½æ•°æ®æ–‡ä»¶...")
        extracted_raw = self.load_json_file(extracted_file)
        existing_raw = self.load_json_file(existing_file)
        
        if extracted_raw is None and existing_raw is None:
            print("âŒ æ— æ³•åŠ è½½ä»»ä½•æ•°æ®æ–‡ä»¶")
            return False
        
        # æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
        extracted_data = self.normalize_extracted_data(extracted_raw) if extracted_raw else []
        existing_data = self.normalize_existing_data(existing_raw) if existing_raw else []
        
        print(f"âœ… æå–æ•°æ®: {len(extracted_data)} ä¸ªåˆ†ç±»")
        print(f"âœ… ç°æœ‰æ•°æ®: {len(existing_data)} ä¸ªåˆ†ç±»")
        
        if not extracted_data and not existing_data:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®å¯ä»¥åˆå¹¶")
            return False
        
        # åˆå¹¶æ•°æ®
        merged_dict = self.merge_categories(extracted_data, existing_data)
        
        # å»é‡
        merged_dict = self.remove_duplicates(merged_dict)
        
        # é‡æ–°åˆ†é…ç¼–å·
        merged_data = self.reassign_numbers(merged_dict)
        
        # ä¿å­˜ç»“æœ
        success = self.save_merged_data(
            merged_data, 
            output_file, 
            extracted_raw if extracted_raw else None
        )
        
        if success:
            # æ˜¾ç¤ºæ‘˜è¦
            self.print_summary(merged_data)
            return True
        
        return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åˆå¹¶ä¿é™©å‘ç‚¹JSONæ–‡ä»¶')
    parser.add_argument('--extracted', '-e',
                       default='../data/insurance_pits_extracted.json',
                       help='æå–çš„å‘ç‚¹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--existing', '-x',
                       default='../data/pit_types_new.json',
                       help='ç°æœ‰å‘ç‚¹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o',
                       default='../data/insurance_pits_merged.json',
                       help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-backup', '-n',
                       action='store_true',
                       help='ä¸åˆ›å»ºå¤‡ä»½æ–‡ä»¶')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    extracted_file = Path(args.extracted)
    existing_file = Path(args.existing)
    
    if not extracted_file.exists() and not existing_file.exists():
        print("âŒ è¾“å…¥æ–‡ä»¶éƒ½ä¸å­˜åœ¨ï¼Œæ— æ³•æ‰§è¡Œåˆå¹¶")
        print(f"æå–æ–‡ä»¶: {extracted_file}")
        print(f"ç°æœ‰æ–‡ä»¶: {existing_file}")
        return 1
    
    # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœéœ€è¦ï¼‰
    output_file = Path(args.output)
    if output_file.exists() and not args.no_backup:
        backup_file = output_file.with_suffix('.backup.json')
        try:
            import shutil
            shutil.copy2(output_file, backup_file)
            print(f"ğŸ“¦ åˆ›å»ºå¤‡ä»½: {backup_file}")
        except Exception as e:
            print(f"âš ï¸  å¤‡ä»½å¤±è´¥: {e}")
    
    # æ‰§è¡Œåˆå¹¶
    merger = PitsMerger()
    success = merger.merge_files(
        str(extracted_file),
        str(existing_file),
        str(output_file)
    )
    
    if success:
        print(f"\nğŸ‰ åˆå¹¶æˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        
        # æ˜¾ç¤ºåç»­å»ºè®®
        print(f"\nğŸ’¡ å»ºè®®æ“ä½œ:")
        print(f"1. æŸ¥çœ‹åˆå¹¶ç»“æœ: cat {output_file} | jq .")
        print(f"2. æ£€æŸ¥æ•°æ®è´¨é‡: jq '.total_pits, .total_categories' {output_file}")
        print(f"3. æŸ¥çœ‹åˆ†ç±»ç»Ÿè®¡: jq '.categories[] | {{category: .category, count: (.items | length)}}' {output_file}")
        
        return 0
    else:
        print(f"\nâŒ åˆå¹¶å¤±è´¥")
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main()) 